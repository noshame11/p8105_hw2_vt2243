---
title: "Homework 2 - Reinforces Ideas in Data Wrangling 1"
author: "Vincent Tam"
date: "October 2, 2018"
output: 
  html_document: default
  github_document: default
---
```{r Setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
```
## Problem 1 - NYC Subways
```{r Reading, Cleaning, Mutating, and Counting Rows/Columns Subway Data, echo = FALSE, include = FALSE}
## Read Data
subway_data = read_csv(file = "./NYC_Transit_Subway_Entrance_AND_Exit_Data.csv")
## Clean, Select, and Mutate
cleaned_subway_data = janitor::clean_names(subway_data)
selected_subway_data = select(cleaned_subway_data, line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) %>% 
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE)) 
## Counting Columns and Rows
nrow(selected_subway_data)
ncol(selected_subway_data)
```
## About this Dataset
The original dataset contained a number of variables that concern the details of the NYC Subway System's stations:  
1. Division
2. Train Line  
3. Station Location Name  
4. Station Latitude  
5. Station Longitude  
6. Route Numbers or Letters Served  
7. Entrance Type  
8. Presence of Entry  
9. Presence of Exit  
10. Presence of Vending  
11. Presence of Staffing  
12. Staff Hours  
13. ADA Compliance    
14. ADA Notes  
15. Presence of Free Crossovers  
16. North-South Streets  
17. East-West Streets  
18. Corner Location  
19. Station Location (Latitude/Longitude)  
20. Entrance Location (Latitude/Longitude)       

The "cleaned" dataset, so far has removed all variables except:  
1. Line  
2. Station Name  
3. Station Location (Latitude/Longitude)  
4. Routes Served  
5. Presence of Entry  
6. Presence of Vending   
7. Entrance Type  
8. ADA compliance.    

Data "cleaning" of the original dataset used the functions "janitor" to clean column names for conversion to lower snake case and "select" to retain desired variables. The "Presence of Entry" variable was converted from character to logical via the "mutate" and "recode" functions.  

The dataset should not be considered "tidy". Routes are not consolidated but spread across eleven different columns.  

The dimension of the cleaned dataset is `r nrow(selected_subway_data)` rows by `r ncol(selected_subway_data)` columns. 
```{r Answer Distinct Subway Stations, echo = FALSE}
## How Many Distinct Subway Stations are There?
counting_stations = distinct(selected_subway_data, line, station_name, ada)
```
There are `r nrow(counting_stations)` distinct subway stations.

There are `r sum(counting_stations$ada)` distinct stations that are ADA compliant.
```{r Proportion of Vending Allow Entrances, echo = FALSE}
## What is the Proportion of Station Entrances/Exits without Vending Allow Entrance?
vending_entrances = selected_subway_data %>%
mutate(vending = recode(vending, "YES" = TRUE, "NO" = FALSE), vending_none = !(vending == entry))
```
`r sum(vending_entrances$vending_none)/nrow(vending_entrances)` is the proportion of station entrances/exits without vending allow entrances. 
```{r Reformat Variables, echo = FALSE}
## Reformat Route Number and Route Name
reformat_number_name = selected_subway_data %>% 
  gather(key = route, value = train, route1:route11) %>%
  separate(route, into = c("remove1", "route"), sep = 5) %>%
  select(everything(), -remove1) %>% 
  distinct(line, station_name, train, ada) %>% 
  filter(train == "A")
```
`r nrow(reformat_number_name)` distinct stations serve the A train.

`r sum(reformat_number_name$ada)` A train stations are ADA compliant.

## Problem 2 - Mr Trash Wheel
## About this Dataset
```{r Reading, Cleaning, and Mutating Data, echo = FALSE}
trash_wheel = readxl::read_excel("./HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N258") %>%
janitor::clean_names(dat = .) %>%
  filter(!is.na(dumpster)) %>%
  mutate(sports_balls = as.integer(sports_balls))
collected = nrow(trash_wheel)*ncol(trash_wheel)
collected
```
Read and clean precipitation data for 2016 and 2017. For each, omit rows without precipitation data and add a variable year. Next, combine datasets and convert month to a character variable (the variable month.name is built into R and should be useful).

Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in both resulting datasets, and give examples of key variables. For available data, what was the total precipitation in 2017? What was the median number of sports balls in a dumpster in 2016?

```{r Reading, Cleaning, and Mutating Data, echo = FALSE}
## Precipitation Data
## 2016
precip_2016 = readxl::read_excel("./HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "2016 Precipitation", range = "A2:B14") %>%
  janitor::clean_names(dat = .) %>%
  mutate(year = 2016) 
nrow(precip_2016)
ncol(precip_2016)
## 2017
precip_2017 = readxl::read_excel("./HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "2017 Precipitation", range = "A2:B14") %>%  
  janitor::clean_names(dat = .) %>%
  mutate(year = 2017)
## Convert Datasets and Convert
precip_2016_2017 = bind_rows(precip_2016, precip_2017)
month_vector =  month.name[c(pull(precip_2016_2017, month))]
month_df = tibble::as.tibble(month_vector) 
final_precip_2016_2017 = bind_cols(precip_2016_2017, month_df) %>%
  select(-month) %>%
  select(year, month = value, total)
## Total Precipitation in 2017
sum(precip_2017$total)
## Median Number of Sports Balls in a Dumpster in 2016
median_balls_2016 = trash_wheel %>% 
  filter(year == 2016) 
median(median_balls_2016$sports_balls)
```
## Problem 3 - BRFFS Data
```{r Installing Dataset, echo = FALSE}
## install.packages("devtools")
## devtools::install_github("p8105/p8105.datasets"); already installed but do not want to install every time
library(p8105.datasets)
data(brfss_smart2010)
## Clean and Wrangle Data
brfss_data = janitor::clean_names(dat = brfss_smart2010) %>%
  filter(topic == "Overall Health") %>%
  select(-(class:question), -sample_size, -(confidence_limit_low:geo_location)) %>%
  spread(key = response, value = data_value) %>%
  janitor::clean_names(dat = .) %>%   
mutate(excellent_verygood = excellent + very_good)
## Answer Questions
## Unique Locations Included in Dataset? Every State Represented? State Observed the Most?
nrow(distinct(brfss_data, locationabbr))
most_observed_state = count(brfss_data, locationabbr) %>%
  top_n(1, n) 
pull(most_observed_state, locationabbr)   
pull(most_observed_state, n)
data_2002 = brfss_data %>% 
  filter(year == 2002)
median(data_2002$excellent, na.rm = TRUE) 
```

```{r Plots, echo = FALSE, warning = FALSE}
## Plotting
## Histogram of Excellent Responses in 2002
ggplot(data_2002, aes(x = excellent)) + geom_histogram(binwidth = 0.75)
## Scatterplot of Excellent Response in New York County and Queens County in Each Year from 2002 to 2010.
brfss_data %>%
  filter(locationdesc %in% c("NY - New York County", "NY - Queens County"), year %in% c("2002":"2012")) %>% ggplot(aes(x = year, y = excellent, color = locationdesc)) + geom_point() + scale_x_continuous(breaks = c(2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010))
```