---
title: "Homework 2 - Reinforces Ideas in Data Wrangling 1"
author: "Vincent Tam"
date: "October 2, 2018"
output: 
  html_document: default
  github_document: default
---
```{r Setup, include = FALSE}
## R Setup
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
```
## Problem 1 - NYC Subway Stations
```{r Reading, Cleaning, Mutating, and Counting Rows/Columns Subway Data, echo = FALSE, include = FALSE}
## Read Subway Station Data
subway_data = read_csv(file = "./NYC_Transit_Subway_Entrance_AND_Exit_Data.csv")
## Clean, Select, and Mutate Data
cleaned_subway_data = janitor::clean_names(subway_data)
selected_subway_data = select(cleaned_subway_data, line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) %>% 
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE)) 
## Counting Dataset Columns and Rows
nrow(selected_subway_data)
ncol(selected_subway_data)
```
### About this Dataset
The original dataset contained a number of variables that concern the details of the NYC Subway System's stations:  
1. Division
2. Train Line  
3. Station Location Name  
4. Station Latitude  
5. Station Longitude  
6. Route Numbers or Letters Served  
7. Entrance Type  
8. Presence of Entry  
9. Presence of Exit  
10. Presence of Vending  
11. Presence of Staffing  
12. Staff Hours  
13. ADA Compliance    
14. ADA Notes  
15. Presence of Free Crossovers  
16. North-South Streets  
17. East-West Streets  
18. Corner Location  
19. Station Location (Latitude/Longitude)  
20. Entrance Location (Latitude/Longitude)       

The "cleaned" dataset, so far has removed all variables except:  
1. Line  
2. Station Name  
3. Station Location (Latitude/Longitude)  
4. Routes Served  
5. Presence of Entry  
6. Presence of Vending   
7. Entrance Type  
8. ADA compliance.    

Data "cleaning" of the original dataset used the functions "janitor" to clean column names for conversion to lower snake case and "select" to retain desired variables. The "Presence of Entry" variable was converted from character to logical via the "mutate" and "recode" functions.  

The dataset should not be considered "tidy". Routes are not consolidated but spread across eleven different columns.  

The dimension of the cleaned dataset is `r nrow(selected_subway_data)` rows by `r ncol(selected_subway_data)` columns. 
```{r Answer Distinct Subway Stations, echo = FALSE}
## How Many Distinct Subway Stations are There?
counting_stations = distinct(selected_subway_data, line, station_name, ada)
```
There are `r nrow(counting_stations)` distinct subway stations.

There are `r sum(counting_stations$ada)` distinct stations that are ADA compliant.
```{r Proportion of Vending Allow Entrances, echo = FALSE}
## What is the Proportion of Station Entrances/Exits without Vending Allow Entrance?
vending_entrances = selected_subway_data %>%
mutate(vending = recode(vending, "YES" = TRUE, "NO" = FALSE), vending_none = !(vending == entry))
```
`r sum(vending_entrances$vending_none)/nrow(vending_entrances)` is the proportion of station entrances/exits without vending allow entrances. 
```{r Reformat Variables, echo = FALSE}
## Reformat Route Number and Route Name
reformat_number_name = selected_subway_data %>% 
  gather(key = route, value = train, route1:route11) %>%
  separate(route, into = c("remove1", "route"), sep = 5) %>%
  select(everything(), -remove1) %>% 
  distinct(line, station_name, train, ada) %>% 
  filter(train == "A")
```
`r nrow(reformat_number_name)` distinct stations serve the A train.

`r sum(reformat_number_name$ada)` A train stations are ADA compliant.

## Problem 2 - Mr Trash Wheel
### About the Datasets
```{r Reading, Cleaning, and Mutating Data for Mr. Trash Wheel, echo = FALSE}
## Read, Clean, and Mutate Mr. Trash Wheel Data
trash_wheel = readxl::read_excel("./HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N258") %>%
janitor::clean_names(dat = .) %>%
  filter(!is.na(dumpster)) %>%
  mutate(sports_balls = as.integer(sports_balls))
```
There are two separate but related datasets in this problem set. The first dataset is about Mr. Trash Wheel cleaning the Baltimore Harbor of man-made refuse. Data in the excel file includes dates, number of dumpster-worth of trash collected, volume and weight of collected garbage, counts of a variety of most common man-made debris collected, and the amount of energy the trash wheel collected in terms of "homes powered" (each ton of trash = approximately 500 kilowatts of electricity and an average home uses 30 kilowatts/day). The dataset contains `r nrow(trash_wheel)` rows by `r ncol(trash_wheel)` columns of data after cleaning and omission of rows that did not include dumpster-specific data and columns containing notes.  
```{r Reading, Cleaning, and Mutating Precipitation Data, echo = FALSE}
## Read, Clean, and Mutate Precipitation Data
## 2016
precip_2016 = readxl::read_excel("./HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "2016 Precipitation", range = "A2:B14") %>%
  janitor::clean_names(dat = .) %>%
  mutate(year = 2016) 
## 2017
precip_2017 = readxl::read_excel("./HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "2017 Precipitation", range = "A2:B14") %>%  
  janitor::clean_names(dat = .) %>%
  mutate(year = 2017)
## Convert Datasets 
precip_2016_2017 = bind_rows(precip_2016, precip_2017)
month_vector =  month.name[c(pull(precip_2016_2017, month))]
month_df = tibble::as.tibble(month_vector) 
final_precip_2016_2017 = bind_cols(precip_2016_2017, month_df) %>%
  select(-month) %>%
  select(year, month = value, total)
```

Although there are other calendar years of data available, only the precipitation datasets for 2016 and 2017 were utilized here. Precipitation data for those two years were cleaned by omitting rows without precipitation data. The datasets were combined and the variable for month was converted to a character variable. There are `r nrow(precip_2016)` rows by `r ncol(precip_2016)` columns of data for year 2016. Year 2017 has `r nrow(precip_2017)` rows by `r ncol(precip_2017)` columns of data. Datasets for both years contained details of total inches of percipitation per calendar month in a year. 

Total precipitation in 2017 was `r sum(precip_2017$total)` inches.
```{r Find Median Number of Sports Balls in a Dumpster in 2016 , echo = FALSE}
median_balls_2016 = trash_wheel %>% 
  filter(year == 2016) 
```
Median number of sports balls collected per dumpster in 2016, rounded to the nearest integer was `r median(median_balls_2016$sports_balls)`.

## Problem 3 - BRFFS Data
```{r Installing Dataset, echo = FALSE}
## Prepare Setup to Answer Problem 3
## install.packages("devtools")
## devtools::install_github("p8105/p8105.datasets"); already installed but do not want to install every time
library(p8105.datasets)
data(brfss_smart2010)
## Clean and Wrangle Data to Prepare for Answering Questions
brfss_data = janitor::clean_names(dat = brfss_smart2010) %>%
  filter(topic == "Overall Health") %>%
  select(-(class:question), -sample_size, -(confidence_limit_low:geo_location)) %>%
  spread(key = response, value = data_value) %>%
  janitor::clean_names(dat = .) %>%   
mutate(excellent_verygood = excellent + very_good)
## Most Observered State (Other than Sleep Deprivation)
most_observed_state = count(brfss_data, locationabbr) %>%
  top_n(1, n) 
```
There are `r nrow(distinct(brfss_data, locationabbr))` unique locations included in this dataset. Every state and the District of Columbia appear to be represented here. The state that appears to be most observed in this dataset is `r pull(most_observed_state, locationabbr)` with a total of `r pull(most_observed_state, n)` observations. 
```{r Find the Median, echo = FALSE}
data_2002 = brfss_data %>% 
  filter(year == 2002)
```
In 2002, the median of the “Excellent” response value was `r median(data_2002$excellent, na.rm = TRUE)`. 

### Plots
#### Histogram of Excellent Response Values in 2002
```{r Histogram Plot, echo = FALSE, warning = FALSE}
## Histogram of Excellent Responses in 2002
ggplot(data_2002, aes(x = excellent)) + geom_histogram(binwidth = 0.75)
```

#### Scatterplot of Proportion of Excellent Response Values in New York County and Queens County in Each Year from 2002 to 2010.
```{r Scatterplot, echo = FALSE, warning = FALSE}
brfss_data %>%
  filter(locationdesc %in% c("NY - New York County", "NY - Queens County"), year %in% c("2002":"2012")) %>% ggplot(aes(x = year, y = excellent, color = locationdesc)) + geom_point() + scale_x_continuous(breaks = c(2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010))
```